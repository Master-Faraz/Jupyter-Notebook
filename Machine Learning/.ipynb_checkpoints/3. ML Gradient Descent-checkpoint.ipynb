{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/1.png)\n",
    "\n",
    "![](images/8.png)\n",
    "<body>\n",
    "\n",
    "<h1 style=\"background-color:powderblue;\">Our purpose is to minimize mean square error</h1>\n",
    "<h1 style=\"background-color:powderblue;\">As Delta canbe ve- so we square them and add all to get MSE</h1>\n",
    "<h1 style=\"background-color:powderblue;\">MSE = mean ( Y_initial  -  Y_predicted )</h1>\n",
    "<h1 style=\"background-color:powderblue;\"> Here ( M * Xi + B ) is Y_predicted</h1>\n",
    "\n",
    "</body>\n",
    "\n",
    "![](images/9.png)\n",
    "\n",
    "![](images/10.png)\n",
    "\n",
    "![](images/11.png)\n",
    "\n",
    "![](images/12.png)\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1 style=\"background-color:powderblue;\">For finding the best line we use gradient descent</h1><br>\n",
    "<h1 style=\"background-color:powderblue;\">In Gradient Descent Algo  -->  We reduce some value of M abd B with some amount until error is minimized to get the line </h1><br>\n",
    "<h1 style=\"background-color:powderblue;\">For getting the maxima we need to get the slope</h1><br>\n",
    "<h1 style=\"background-color:powderblue;\"> Y = M * X + B   where M is slope and X and B is intercept </h1><br>\n",
    "\n",
    "</body>\n",
    "\n",
    "![](images/13.png)\n",
    "\n",
    "![](images/14.png)\n",
    "\n",
    "![](images/15.png)\n",
    "\n",
    "![](images/16.png)\n",
    "\n",
    "![](images/17.png)\n",
    "\n",
    "\n",
    "<body>\n",
    "\n",
    "<h1 style=\"background-color:powderblue;\">For getting slope we find partial derivative</h1><br>\n",
    "<h1 style=\"background-color:powderblue;\">Partial Derivative gies the slope or direction </h1><br>\n",
    "<h1 style=\"background-color:powderblue;\">For taking steps we use Learning Rate </h1><br>\n",
    "\n",
    "</body>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x,y):\n",
    "    m_curr = b_curr =0       # Start with some value of M and B\n",
    "    iterations = 2000       # Iterations to reach minima\n",
    "    n = len(x)               # Length of array or dataset\n",
    "    learning_rate = 0.06    # Steps to reach minima \n",
    "    \n",
    "    minimum = (1/n) * sum([val**2 for val in (y-(m_curr * x +b_curr))])     # Minimum = Error\n",
    "    \n",
    "    for i in range(iterations):  \n",
    "        m_prev=m_curr\n",
    "        b_prev=b_curr\n",
    "\n",
    "        y_pred = m_curr * x +b_curr     #  Y = MX + C\n",
    "        md = -(2/n)*sum(x*(y-y_pred))   # M partial derivative\n",
    "        bd = -(2/n)*sum((y-y_pred))   # B partial derivative\n",
    "        error = (1/n) * sum([val**2 for val in (y-y_pred)])   #   Or cost function\n",
    "\n",
    "\n",
    "\n",
    "        if(error>minimum):\n",
    "            print(f\"Slope M : {m_prev} and Intercept B : {b_prev} \")\n",
    "            break\n",
    "        if(error<minimum):            \n",
    "            minimum=error\n",
    "\n",
    "        \n",
    "\n",
    "        m_curr = m_curr -learning_rate * md\n",
    "        b_curr = b_curr -learning_rate * bd\n",
    "        \n",
    "#         print(f\"Error : {error} \\t m : {m_curr} \\t b : {b_curr} \\t Iterations {i}\")\n",
    "        # We keep on reducing error ::  by increasing iterationsns \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope M : 2.0000000000000133 and Intercept B : 2.9999999999999516 \n",
      "\n",
      "\n",
      "Time taken is : 0.0336763858795166\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=np.array([1,2,3,4,5])\n",
    "y=np.array([5,7,9,11,13])\n",
    "\n",
    "\n",
    "t1=time.time()\n",
    "\n",
    "grad(x,y)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print(f\"\\n\\nTime taken is : {t2-t1}\\n\\n\")\n",
    "    \n",
    "    \n",
    "# \"\"\"\n",
    "# 1 > We check by decreasing or increasing Learning Rate\n",
    "# 2 > when error starts increasing that will be our upper_boundry  ex at learning rate 0.1 , iteration 100\n",
    "# 3 > When boundry is found then we decrease the learning rate and increasing iterations to get optimal value where error is minimum\n",
    "# 4 > at 0.06 and 2000  we get M_curr ~=2 , B_curr ~= 3 \n",
    "# 5 > Y = 2x + 3    is the equation\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
